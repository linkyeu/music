{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html#early_stopping_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('scripts')\n",
    "from common import *\n",
    "from global_common import *\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (70134, 460)\n",
      "Shape of test (30058, 460)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Читаем данные\n",
    "path_to_data = Path('../data')\n",
    "train_df = pd.read_csv(path_to_data/'train_music.csv')\n",
    "train_y = train_df['target']\n",
    "del train_df['target']\n",
    "\n",
    "test_df  = pd.read_csv(path_to_data/'test_music.csv')\n",
    "\n",
    "sample_submission_df = pd.read_csv(path_to_data/'sample_submission_music.csv')\n",
    "print(f'Shape of train {train_df.shape}\\nShape of test {test_df.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бинарных признаков - 15\n",
      "Категориальных признаков - 5\n",
      "Числовых признаков - 439\n"
     ]
    }
   ],
   "source": [
    "# Объединяем выборки для обработки переменных, запоминаем индексы чтобы потом разделить назад\n",
    "train_idx = train_df.index[-1]\n",
    "merged = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# Бинарный признка целочисленное значение, пропуски = -1, не эмбединги\n",
    "binary_columns = [o for o in merged.columns if 'flag' in o or 'is' in o]\n",
    "binary_columns.remove('tp_flag')\n",
    "print(f'Бинарных признаков - {len(binary_columns)}')\n",
    "\n",
    "# Для категориальных признаков используем -1. Кодируем в эмбединги. Целочисленные значения.\n",
    "cat_names = ['sim_count', 'device_type', 'manufacturer_category', 'os_category', 'tp_flag']\n",
    "print(f'Категориальных признаков - {len(cat_names)}')\n",
    "\n",
    "# Флоат должны использовать медиану для замещения пропусков\n",
    "float_columns = list(set(merged.columns).difference(set(binary_columns+cat_names)))\n",
    "float_columns.remove('id')\n",
    "print(f'Числовых признаков - {len(float_columns)}')\n",
    "\n",
    "# Замещаем пропущенные значения в соответствии с типом данных\n",
    "merged[binary_columns] = merged[binary_columns].apply(lambda x: x.fillna(-1))\n",
    "merged[cat_names] = merged[cat_names].apply(lambda x: x.fillna(-1))\n",
    "merged[float_columns] = merged[float_columns].apply(lambda x: x.fillna(x.median()))\n",
    "assert merged.isna().sum().sum() == 0, 'Buddy, slow down!'\n",
    "\n",
    "# Присваивает тип для каждой из переменных\n",
    "merged[binary_columns] = merged[binary_columns].apply(lambda x: x.astype('int'))\n",
    "merged[cat_names] = merged[cat_names].apply(lambda x: x.astype('int'))\n",
    "merged[float_columns] = merged[float_columns].apply(lambda x: x.astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем обработанные обучающую и тестовую выборки\n",
    "train = merged.iloc[:train_idx+1, :]\n",
    "train['target'] = train_y\n",
    "test = merged.iloc[train_idx+1:, :]\n",
    "del merged\n",
    "del train_y\n",
    "\n",
    "# Указываем для модели категориальные (для кодировки в эмб) и числовые\n",
    "dep_var = 'target'\n",
    "cont_names = float_columns\n",
    "cat_names = cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30058, 460),\n",
       " Index(['id', 'device_type', 'manufacturer_category', 'os_category',\n",
       "        'sim_count', 'tp_flag', 'lt', 'block_flag', 'days_exp',\n",
       "        'service_1_flag',\n",
       "        ...\n",
       "        'service_5_count_m3', 'service_6_count_m3', 'service_7_cost_m3',\n",
       "        'service_7_flag_m3', 'service_8_count_m3', 'income_brnd_cont_m3',\n",
       "        'data_type_1_m3', 'data_type_2_m3', 'data_type_3_m3',\n",
       "        'service_9_flag_m3'],\n",
       "       dtype='object', length=460))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare dataset for training\n",
    "cols_to_drop = [\n",
    "    'id',\n",
    "    'target',\n",
    "]\n",
    "\n",
    "categorical = cat_names\n",
    "\n",
    "X = train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "y = train.target.values\n",
    "\n",
    "id_test = test.id.values\n",
    "X_test = test.drop(cols_to_drop[0], axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "# print('train.shape = {}, test.shape = {}'.format(train.shape, test.shape))\n",
    "\n",
    "# lgb_params = {\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': 'auc',\n",
    "#     'max_depth': 5,\n",
    "#     'learning_rate': 0.01, \n",
    "#     'verbose': -1,\n",
    "#     'num_threads': 2,\n",
    "# #     'scale_pos_weight' : int(train.target.mean()*10),\n",
    "#     'is_unbalance' : 'true',\n",
    "# }\n",
    "\n",
    "# # Build the model\n",
    "# cnt = 0\n",
    "# p_buf = []\n",
    "# n_splits = 5\n",
    "# n_repeats = 1\n",
    "# kf = StratifiedKFold(\n",
    "#     n_splits=n_splits, \n",
    "#     random_state=0)\n",
    "# err_buf = []   \n",
    "\n",
    "# n_features = X.shape[1]\n",
    "\n",
    "# for train_index, valid_index in kf.split(X, y):\n",
    "#     print('Fold {}/{}*{}'.format(cnt + 1, n_splits, n_repeats))\n",
    "#     params = lgb_params.copy() \n",
    "    \n",
    "#     lgb_train = lgb.Dataset(\n",
    "#         X.iloc[train_index], \n",
    "#         y[train_index], \n",
    "#         categorical_feature=categorical,\n",
    "    \n",
    "#         )\n",
    "#     lgb_train.raw_data = None\n",
    "\n",
    "#     lgb_valid = lgb.Dataset(\n",
    "#         X.iloc[valid_index], \n",
    "#         y[valid_index],\n",
    "#         categorical_feature=categorical,\n",
    "#         )\n",
    "#     lgb_valid.raw_data = None\n",
    "\n",
    "#     model = lgb.train(\n",
    "#         params,\n",
    "#         lgb_train,\n",
    "#         num_boost_round=100000,\n",
    "#         valid_sets=[lgb_train, lgb_valid],\n",
    "#         early_stopping_rounds=150, \n",
    "#         verbose_eval=100,\n",
    "#     )\n",
    "\n",
    "#     if cnt == 0:\n",
    "#         importance = model.feature_importance()\n",
    "#         model_fnames = model.feature_name()\n",
    "#         tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "#         tuples = [x for x in tuples if x[1] > 0]\n",
    "#         print('Important features:')\n",
    "#         for i in range(60):\n",
    "#             if i < len(tuples):\n",
    "#                 print(tuples[i])\n",
    "#             else:\n",
    "#                 break\n",
    "\n",
    "#         del importance, model_fnames, tuples\n",
    "\n",
    "#     p = model.predict(X.iloc[valid_index], num_iteration=model.best_iteration)\n",
    "#     err = roc_auc_score(y[valid_index], p)\n",
    "\n",
    "#     print('{} auc: {}'.format(cnt + 1, err))\n",
    "\n",
    "#     p = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "#     if len(p_buf) == 0:\n",
    "#         p_buf = np.array(p, dtype=np.float16)\n",
    "#     else:\n",
    "#         p_buf += np.array(p, dtype=np.float16)\n",
    "#     err_buf.append(err)\n",
    "\n",
    "\n",
    "#     cnt += 1\n",
    "#     # if cnt > 0: # Comment this to run several folds\n",
    "#     #     break\n",
    "\n",
    "#     del model, lgb_train, lgb_valid, p\n",
    "#     gc.collect\n",
    "\n",
    "# err_mean = np.mean(err_buf)\n",
    "# err_std = np.std(err_buf)\n",
    "# print('auc = {:.6f} +/- {:.6f}'.format(err_mean, err_std))\n",
    "\n",
    "# preds = p_buf/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Split\n",
    "# 5 auc: 0.8265728454896974\n",
    "# auc = 0.837760 +/- 0.009300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_pos_weight : 99 + stratify\n",
    "# 5 auc: 0.8009548197291523\n",
    "# auc = 0.810203 +/- 0.011326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_inbalanceb  + stratify\n",
    "# 5 auc: 0.8211641682998747\n",
    "# auc = 0.833885 +/- 0.010785  LB = 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_inbalanceb  + stratify + categorical\n",
    "# 5 auc: 0.8226285930575419\n",
    "# auc = 0.834418 +/- 0.010447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = id_test\n",
    "subm['prediction'] = preds\n",
    "subm.to_csv('submissions/lightgbm2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0\n",
    "# https://www.kaggle.com/eikedehling/tune-and-compare-xgb-lightgbm-rf-with-hyperopt\n",
    "# https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Introduction%20to%20Bayesian%20Optimization%20with%20Hyperopt.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params:\")\n",
    "    print(params)\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    dtrain = lgb.Dataset(X.iloc[train_idxs, :], y[train_idxs])\n",
    "    dvalid = lgb.Dataset(X.iloc[valid_idxs, :], y[valid_idxs])\n",
    "    model = lgb.train(params, dtrain, params['num_round'])\n",
    "    predictions = model.predict(X.iloc[valid_idxs, :]) # возможно здесь нужно 2 поставить\n",
    "    score = roc_auc_score(y[valid_idxs], predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'num_round': 100,\n",
    "             'learning_rate': hp.quniform('eta', 0.005, 0.05, 0.005),\n",
    "#              'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "             'max_depth': hp.quniform('max_depth', 3, 14, 1),\n",
    "#              'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "#              'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "#              'colsample_bytree': hp.quniform('colsample_bytree', 0.4, 1, 0.05),\n",
    "             'num_class' : 1,\n",
    "             'metric': 'auc',\n",
    "             'objective': 'binary',\n",
    "             #     'scale_pos_weight' : int(train.target.mean()*10),\n",
    "             'nthread' : 8,\n",
    "             'silent' : 1,\n",
    "             'is_unbalance' : hp.choice('is_unbalance', [None, 'true']),\n",
    "#              'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "             }\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=10)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idxs, valid_idxs, _, _ = train_test_split(X.index, y, \n",
    "#                                     stratify=y,\n",
    "#                                     test_size=0.3, \n",
    "#                                     random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials = Trials()\n",
    "# best_params = optimize(trials)\n",
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = (70134, 461), test.shape = (30058, 460)\n",
      "Fold 1/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.81409\tvalid_1's auc: 0.806449\n",
      "[200]\ttraining's auc: 0.831581\tvalid_1's auc: 0.82035\n",
      "[300]\ttraining's auc: 0.844504\tvalid_1's auc: 0.828991\n",
      "[400]\ttraining's auc: 0.85433\tvalid_1's auc: 0.834286\n",
      "[500]\ttraining's auc: 0.862766\tvalid_1's auc: 0.837877\n",
      "[600]\ttraining's auc: 0.870177\tvalid_1's auc: 0.840412\n",
      "[700]\ttraining's auc: 0.876567\tvalid_1's auc: 0.841805\n",
      "[800]\ttraining's auc: 0.882212\tvalid_1's auc: 0.842483\n",
      "[900]\ttraining's auc: 0.887512\tvalid_1's auc: 0.842897\n",
      "[1000]\ttraining's auc: 0.89235\tvalid_1's auc: 0.843156\n",
      "[1100]\ttraining's auc: 0.896714\tvalid_1's auc: 0.84336\n",
      "[1200]\ttraining's auc: 0.90076\tvalid_1's auc: 0.8435\n",
      "[1300]\ttraining's auc: 0.904581\tvalid_1's auc: 0.84344\n",
      "Early stopping, best iteration is:\n",
      "[1190]\ttraining's auc: 0.900399\tvalid_1's auc: 0.843549\n",
      "Important features:\n",
      "('manufacturer_category', 1486)\n",
      "('data_type_2_m1', 964)\n",
      "('data_type_3_m1', 768)\n",
      "('data_type_1_m1', 718)\n",
      "('content_count_m1', 639)\n",
      "('lt', 443)\n",
      "('balance_sum', 335)\n",
      "('content_count_m3', 327)\n",
      "('vol_app_7', 270)\n",
      "('count_act_type_1', 263)\n",
      "('count_app_5', 263)\n",
      "('data_type_2_m3', 258)\n",
      "('data_type_1_m3', 237)\n",
      "('data_type_1_m2', 209)\n",
      "('content_count_m2', 205)\n",
      "('count_app_4', 200)\n",
      "('vol_app_4', 186)\n",
      "('service_1_count', 185)\n",
      "('count_sms_source_4', 159)\n",
      "('sms_in_count_m2', 157)\n",
      "('service_1_flag', 142)\n",
      "('all_cost_m1', 131)\n",
      "('vol_app_1', 131)\n",
      "('sms_in_count_m1', 127)\n",
      "('paym_el_sum_m1', 122)\n",
      "('all_count_m2', 117)\n",
      "('is_obl_center', 112)\n",
      "('count_app_9', 108)\n",
      "('vol_app_12', 104)\n",
      "('all_count_m3', 102)\n",
      "('count_url_category_4', 101)\n",
      "('sms_in_count_m3', 100)\n",
      "('sms_cost_m3', 99)\n",
      "('count_gift_type_4', 98)\n",
      "('short_out_calls_part_m1', 97)\n",
      "('content_cost_m1', 97)\n",
      "('short_out_calls_part_m3', 95)\n",
      "('count_sms_source_15', 88)\n",
      "('data_type_2_m2', 86)\n",
      "('count_app_10', 85)\n",
      "('service_P_flag_m2', 84)\n",
      "('count_url_category_7', 83)\n",
      "('data_type_3_m2', 80)\n",
      "('vol_app_10', 80)\n",
      "('paym_el_sum_m3', 76)\n",
      "('all_cost_m2', 75)\n",
      "('act_days_count_m3', 73)\n",
      "('service_9_flag_m1', 73)\n",
      "('vol_app_15', 72)\n",
      "('count_gift_type_1', 71)\n",
      "('count_url_category_9', 71)\n",
      "('count_url_category_2', 69)\n",
      "('count_act_type_8', 68)\n",
      "('count_app_15', 66)\n",
      "('count_sms_source_5', 66)\n",
      "('count_act_type_7', 65)\n",
      "('short_in_calls_part_m3', 64)\n",
      "('voice_pstn_out_dur_m1', 62)\n",
      "('service_P_flag_m1', 62)\n",
      "('count_app_6', 62)\n",
      "1 auc: 0.8435485134574474\n",
      "Fold 2/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.819113\tvalid_1's auc: 0.786158\n",
      "[200]\ttraining's auc: 0.835641\tvalid_1's auc: 0.798204\n",
      "[300]\ttraining's auc: 0.848468\tvalid_1's auc: 0.806693\n",
      "[400]\ttraining's auc: 0.857768\tvalid_1's auc: 0.811087\n",
      "[500]\ttraining's auc: 0.865992\tvalid_1's auc: 0.81447\n",
      "[600]\ttraining's auc: 0.872995\tvalid_1's auc: 0.816305\n",
      "[700]\ttraining's auc: 0.879286\tvalid_1's auc: 0.817962\n",
      "[800]\ttraining's auc: 0.884758\tvalid_1's auc: 0.818919\n",
      "[900]\ttraining's auc: 0.889574\tvalid_1's auc: 0.819721\n",
      "[1000]\ttraining's auc: 0.893947\tvalid_1's auc: 0.820332\n",
      "[1100]\ttraining's auc: 0.898112\tvalid_1's auc: 0.820585\n",
      "[1200]\ttraining's auc: 0.902226\tvalid_1's auc: 0.820465\n",
      "Early stopping, best iteration is:\n",
      "[1129]\ttraining's auc: 0.899321\tvalid_1's auc: 0.820658\n",
      "2 auc: 0.8206576119099954\n",
      "Fold 3/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.815449\tvalid_1's auc: 0.809613\n",
      "[200]\ttraining's auc: 0.831897\tvalid_1's auc: 0.82284\n",
      "[300]\ttraining's auc: 0.844662\tvalid_1's auc: 0.831899\n",
      "[400]\ttraining's auc: 0.854322\tvalid_1's auc: 0.836522\n",
      "[500]\ttraining's auc: 0.862459\tvalid_1's auc: 0.839221\n",
      "[600]\ttraining's auc: 0.869983\tvalid_1's auc: 0.841419\n",
      "[700]\ttraining's auc: 0.876527\tvalid_1's auc: 0.843386\n",
      "[800]\ttraining's auc: 0.882435\tvalid_1's auc: 0.844058\n",
      "[900]\ttraining's auc: 0.887508\tvalid_1's auc: 0.844662\n",
      "[1000]\ttraining's auc: 0.891972\tvalid_1's auc: 0.8447\n",
      "[1100]\ttraining's auc: 0.89635\tvalid_1's auc: 0.844709\n",
      "[1200]\ttraining's auc: 0.900555\tvalid_1's auc: 0.844632\n",
      "Early stopping, best iteration is:\n",
      "[1055]\ttraining's auc: 0.894448\tvalid_1's auc: 0.844826\n",
      "3 auc: 0.8448262316499386\n",
      "Fold 4/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.817\tvalid_1's auc: 0.799872\n",
      "[200]\ttraining's auc: 0.833186\tvalid_1's auc: 0.814373\n",
      "[300]\ttraining's auc: 0.845454\tvalid_1's auc: 0.823984\n",
      "[400]\ttraining's auc: 0.855574\tvalid_1's auc: 0.829935\n",
      "[500]\ttraining's auc: 0.86414\tvalid_1's auc: 0.833572\n",
      "[600]\ttraining's auc: 0.871446\tvalid_1's auc: 0.835502\n",
      "[700]\ttraining's auc: 0.877824\tvalid_1's auc: 0.837177\n",
      "[800]\ttraining's auc: 0.883591\tvalid_1's auc: 0.838265\n",
      "[900]\ttraining's auc: 0.888566\tvalid_1's auc: 0.838917\n",
      "[1000]\ttraining's auc: 0.893048\tvalid_1's auc: 0.839196\n",
      "[1100]\ttraining's auc: 0.897214\tvalid_1's auc: 0.839453\n",
      "[1200]\ttraining's auc: 0.90124\tvalid_1's auc: 0.839906\n",
      "[1300]\ttraining's auc: 0.905016\tvalid_1's auc: 0.840162\n",
      "[1400]\ttraining's auc: 0.908928\tvalid_1's auc: 0.840328\n",
      "[1500]\ttraining's auc: 0.91258\tvalid_1's auc: 0.840445\n",
      "[1600]\ttraining's auc: 0.915923\tvalid_1's auc: 0.840382\n",
      "[1700]\ttraining's auc: 0.91922\tvalid_1's auc: 0.840497\n",
      "[1800]\ttraining's auc: 0.922174\tvalid_1's auc: 0.840584\n",
      "[1900]\ttraining's auc: 0.925044\tvalid_1's auc: 0.840472\n",
      "Early stopping, best iteration is:\n",
      "[1777]\ttraining's auc: 0.921495\tvalid_1's auc: 0.840611\n",
      "4 auc: 0.8406110140091628\n",
      "Fold 5/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.820737\tvalid_1's auc: 0.789432\n",
      "[200]\ttraining's auc: 0.837211\tvalid_1's auc: 0.801431\n",
      "[300]\ttraining's auc: 0.849215\tvalid_1's auc: 0.810024\n",
      "[400]\ttraining's auc: 0.858908\tvalid_1's auc: 0.815031\n",
      "[500]\ttraining's auc: 0.866843\tvalid_1's auc: 0.817818\n",
      "[600]\ttraining's auc: 0.87408\tvalid_1's auc: 0.819908\n",
      "[700]\ttraining's auc: 0.88032\tvalid_1's auc: 0.820832\n",
      "[800]\ttraining's auc: 0.885878\tvalid_1's auc: 0.821497\n",
      "[900]\ttraining's auc: 0.890914\tvalid_1's auc: 0.821595\n",
      "[1000]\ttraining's auc: 0.895418\tvalid_1's auc: 0.821738\n",
      "[1100]\ttraining's auc: 0.899516\tvalid_1's auc: 0.821911\n",
      "[1200]\ttraining's auc: 0.903373\tvalid_1's auc: 0.821861\n",
      "Early stopping, best iteration is:\n",
      "[1119]\ttraining's auc: 0.900287\tvalid_1's auc: 0.821949\n",
      "5 auc: 0.8219485495347565\n",
      "auc = 0.834318 +/- 0.010722\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for training\n",
    "cols_to_drop = [\n",
    "    'id',\n",
    "    'target',\n",
    "]\n",
    "\n",
    "categorical = cat_names\n",
    "\n",
    "X = train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "y = train.target.values\n",
    "\n",
    "id_test = test.id.values\n",
    "X_test = test.drop(cols_to_drop[0], axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "print('train.shape = {}, test.shape = {}'.format(train.shape, test.shape))\n",
    "\n",
    "lgb_params = {\n",
    "    'num_leaves' : 16,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.01, \n",
    "    'verbose': -1,\n",
    "    'num_threads': 8,\n",
    "#     'is_unbalance' : 'true',\n",
    "    'scale_pos_weight' : 9,\n",
    "\n",
    "}\n",
    "\n",
    "# Build the model\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "kf = StratifiedKFold(\n",
    "    n_splits=n_splits, \n",
    "    random_state=0)\n",
    "err_buf = []   \n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "for train_index, valid_index in kf.split(X, y):\n",
    "    print('Fold {}/{}*{}'.format(cnt + 1, n_splits, n_repeats))\n",
    "    params = lgb_params.copy() \n",
    "    \n",
    "    lgb_train = lgb.Dataset(\n",
    "        X.iloc[train_index], \n",
    "        y[train_index], \n",
    "        categorical_feature=categorical,\n",
    "    \n",
    "        )\n",
    "    lgb_train.raw_data = None\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        X.iloc[valid_index], \n",
    "        y[valid_index],\n",
    "        categorical_feature=categorical,\n",
    "        )\n",
    "    lgb_valid.raw_data = None\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=100000,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        early_stopping_rounds=150, \n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    if cnt == 0:\n",
    "        importance = model.feature_importance()\n",
    "        model_fnames = model.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1] > 0]\n",
    "        print('Important features:')\n",
    "        for i in range(60):\n",
    "            if i < len(tuples):\n",
    "                print(tuples[i])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        del importance, model_fnames, tuples\n",
    "\n",
    "    p = model.predict(X.iloc[valid_index], num_iteration=model.best_iteration)\n",
    "    err = roc_auc_score(y[valid_index], p)\n",
    "\n",
    "    print('{} auc: {}'.format(cnt + 1, err))\n",
    "\n",
    "    p = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p, dtype=np.float16)\n",
    "    else:\n",
    "        p_buf += np.array(p, dtype=np.float16)\n",
    "    err_buf.append(err)\n",
    "\n",
    "\n",
    "    cnt += 1\n",
    "    # if cnt > 0: # Comment this to run several folds\n",
    "    #     break\n",
    "\n",
    "    del model, lgb_train, lgb_valid, p\n",
    "    gc.collect\n",
    "\n",
    "err_mean = np.mean(err_buf)\n",
    "err_std = np.std(err_buf)\n",
    "print('auc = {:.6f} +/- {:.6f}'.format(err_mean, err_std))\n",
    "\n",
    "preds = p_buf/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = id_test\n",
    "subm['prediction'] = preds\n",
    "subm.to_csv('submissions/new_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    from sklearn.metrics import log_loss\n",
    "    print(\"Training with params:\")\n",
    "    print(params)\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    dtrain = xgb.DMatrix(X.iloc[train_idxs, :], y[train_idxs])\n",
    "    dvalid = xgb.DMatrix(X.iloc[valid_idxs, :], y[valid_idxs])\n",
    "    model = xgb.train(params, dtrain, params['num_round'])\n",
    "    predictions = model.predict(dvalid)\n",
    "    score = roc_auc_score(y[valid_idxs], predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'num_round': 100,\n",
    "             'learning_rate': hp.quniform('eta', 0.005, 0.05, 0.005),\n",
    "             'max_depth': hp.quniform('max_depth', 3, 14, 1),\n",
    "             'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "             'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma': hp.quniform('gamma', 0.5, 1, 0.01),\n",
    "             'colsample_bytree': hp.quniform('colsample_bytree', 0.4, 1, 0.05),\n",
    "             'num_class' : 1,\n",
    "             'eval_metric': 'auc',\n",
    "#              'objective': 'linear',\n",
    "             'nthread' : 8,\n",
    "             'silent' : 1\n",
    "             }\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=10)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials = Trials()\n",
    "# best_params = optimize(trials)\n",
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
