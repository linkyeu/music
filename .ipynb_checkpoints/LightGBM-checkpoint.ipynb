{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь про короля - LightGBM. Загрузил данные, запустил в ГБМ, покрутил немного параметры.\n",
    "Теперь нужно провести его тонкую настройку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('scripts')\n",
    "from common import *\n",
    "from global_common import *\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (70134, 460)\n",
      "Shape of test (30001, 460)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Читаем данные\n",
    "path_to_data = Path('../data')\n",
    "train_df = pd.read_csv(path_to_data/'train_music.csv')\n",
    "train_y = train_df['target']\n",
    "del train_df['target']\n",
    "\n",
    "test_df  = pd.read_csv(path_to_data/'test_music.csv')\n",
    "\n",
    "sample_submission_df = pd.read_csv(path_to_data/'sample_submission_music.csv')\n",
    "print(f'Shape of train {train_df.shape}\\nShape of test {test_df.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бинарных признаков - 15\n",
      "Категориальных признаков - 5\n",
      "Числовых признаков - 439\n"
     ]
    }
   ],
   "source": [
    "# Объединяем выборки для обработки переменных, запоминаем индексы чтобы потом разделить назад\n",
    "train_idx = train_df.index[-1]\n",
    "merged = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# Бинарный признка целочисленное значение, пропуски = -1, не эмбединги\n",
    "binary_columns = [o for o in merged.columns if 'flag' in o or 'is' in o]\n",
    "binary_columns.remove('tp_flag')\n",
    "print(f'Бинарных признаков - {len(binary_columns)}')\n",
    "\n",
    "# Для категориальных признаков используем -1. Кодируем в эмбединги. Целочисленные значения.\n",
    "cat_names = ['sim_count', 'device_type', 'manufacturer_category', 'os_category', 'tp_flag']\n",
    "print(f'Категориальных признаков - {len(cat_names)}')\n",
    "\n",
    "# Флоат должны использовать медиану для замещения пропусков\n",
    "float_columns = list(set(merged.columns).difference(set(binary_columns+cat_names)))\n",
    "float_columns.remove('id')\n",
    "print(f'Числовых признаков - {len(float_columns)}')\n",
    "\n",
    "# Замещаем пропущенные значения в соответствии с типом данных\n",
    "merged[binary_columns] = merged[binary_columns].apply(lambda x: x.fillna(-1))\n",
    "merged[cat_names] = merged[cat_names].apply(lambda x: x.fillna(-1))\n",
    "merged[float_columns] = merged[float_columns].apply(lambda x: x.fillna(x.median()))\n",
    "assert merged.isna().sum().sum() == 0, 'Buddy, slow down!'\n",
    "\n",
    "# Присваивает тип для каждой из переменных\n",
    "merged[binary_columns] = merged[binary_columns].apply(lambda x: x.astype('int'))\n",
    "merged[cat_names] = merged[cat_names].apply(lambda x: x.astype('int'))\n",
    "merged[float_columns] = merged[float_columns].apply(lambda x: x.astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем обработанные обучающую и тестовую выборки\n",
    "train = merged.iloc[:train_idx+1, :]\n",
    "train['target'] = train_y\n",
    "test = merged.iloc[train_idx+1:, :]\n",
    "del merged\n",
    "del train_y\n",
    "\n",
    "# Указываем для модели категориальные (для кодировки в эмб) и числовые\n",
    "dep_var = 'target'\n",
    "cont_names = float_columns\n",
    "cat_names = cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = (70134, 461), test.shape = (30001, 460)\n",
      "Fold 1/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.833433\tvalid_1's auc: 0.81129\n",
      "[200]\ttraining's auc: 0.851859\tvalid_1's auc: 0.823689\n",
      "[300]\ttraining's auc: 0.866192\tvalid_1's auc: 0.832551\n",
      "[400]\ttraining's auc: 0.877289\tvalid_1's auc: 0.836772\n",
      "[500]\ttraining's auc: 0.887401\tvalid_1's auc: 0.839853\n",
      "[600]\ttraining's auc: 0.894883\tvalid_1's auc: 0.841458\n",
      "[700]\ttraining's auc: 0.901537\tvalid_1's auc: 0.842491\n",
      "[800]\ttraining's auc: 0.907523\tvalid_1's auc: 0.842797\n",
      "[900]\ttraining's auc: 0.91275\tvalid_1's auc: 0.842801\n",
      "[1000]\ttraining's auc: 0.917337\tvalid_1's auc: 0.842913\n",
      "[1100]\ttraining's auc: 0.9219\tvalid_1's auc: 0.84311\n",
      "[1200]\ttraining's auc: 0.925725\tvalid_1's auc: 0.843207\n",
      "[1300]\ttraining's auc: 0.929416\tvalid_1's auc: 0.843126\n",
      "Early stopping, best iteration is:\n",
      "[1243]\ttraining's auc: 0.927455\tvalid_1's auc: 0.843341\n",
      "Important features:\n",
      "('manufacturer_category', 1861)\n",
      "('data_type_3_m1', 1378)\n",
      "('data_type_2_m1', 1344)\n",
      "('data_type_1_m1', 1302)\n",
      "('lt', 1008)\n",
      "('content_count_m1', 931)\n",
      "('balance_sum', 592)\n",
      "('content_count_m3', 586)\n",
      "('count_app_5', 449)\n",
      "('data_type_2_m3', 419)\n",
      "('vol_app_7', 406)\n",
      "('count_act_type_1', 346)\n",
      "('data_type_1_m3', 341)\n",
      "('content_count_m2', 337)\n",
      "('count_app_4', 311)\n",
      "('service_1_count', 308)\n",
      "('vol_app_4', 294)\n",
      "('all_cost_m1', 263)\n",
      "('vol_app_1', 260)\n",
      "('data_type_1_m2', 252)\n",
      "('count_sms_source_4', 242)\n",
      "('all_count_m3', 234)\n",
      "('sms_in_count_m2', 231)\n",
      "('paym_el_sum_m1', 223)\n",
      "('data_type_3_m2', 216)\n",
      "('data_type_2_m2', 215)\n",
      "('all_cost_m2', 186)\n",
      "('data_type_3_m3', 183)\n",
      "('vol_app_10', 181)\n",
      "('service_1_flag', 178)\n",
      "('sms_in_count_m1', 174)\n",
      "('count_app_1', 171)\n",
      "('sms_in_count_m3', 170)\n",
      "('short_in_calls_part_m3', 165)\n",
      "('count_app_15', 165)\n",
      "('count_app_10', 164)\n",
      "('count_url_category_2', 163)\n",
      "('vol_app_12', 162)\n",
      "('short_in_calls_part_m2', 161)\n",
      "('days_exp', 158)\n",
      "('short_out_calls_part_m3', 149)\n",
      "('count_app_7', 149)\n",
      "('sms_cost_m3', 147)\n",
      "('short_out_calls_part_m1', 146)\n",
      "('paym_el_sum_m3', 142)\n",
      "('count_app_9', 142)\n",
      "('is_obl_center', 140)\n",
      "('all_count_m2', 139)\n",
      "('vol_app_15', 138)\n",
      "('vol_app_5', 138)\n",
      "('count_url_category_4', 138)\n",
      "('all_home_clc_m3', 132)\n",
      "('content_cost_m1', 132)\n",
      "('voice_onnet_out_night_work_dur_m1', 124)\n",
      "('vol_app_6', 123)\n",
      "('vol_app_9', 121)\n",
      "('count_url_category_7', 120)\n",
      "('all_home_clc_m1', 117)\n",
      "('count_gift_type_4', 116)\n",
      "('count_sms_source_15', 116)\n",
      "1 auc: 0.8433413994156227\n",
      "Fold 2/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.838322\tvalid_1's auc: 0.791451\n",
      "[200]\ttraining's auc: 0.85519\tvalid_1's auc: 0.80184\n",
      "[300]\ttraining's auc: 0.870388\tvalid_1's auc: 0.810633\n",
      "[400]\ttraining's auc: 0.881052\tvalid_1's auc: 0.81492\n",
      "[500]\ttraining's auc: 0.890899\tvalid_1's auc: 0.817365\n",
      "[600]\ttraining's auc: 0.899164\tvalid_1's auc: 0.818515\n",
      "[700]\ttraining's auc: 0.905684\tvalid_1's auc: 0.819441\n",
      "[800]\ttraining's auc: 0.910814\tvalid_1's auc: 0.820062\n",
      "[900]\ttraining's auc: 0.915437\tvalid_1's auc: 0.820554\n",
      "[1000]\ttraining's auc: 0.919804\tvalid_1's auc: 0.820879\n",
      "[1100]\ttraining's auc: 0.923799\tvalid_1's auc: 0.820865\n",
      "Early stopping, best iteration is:\n",
      "[977]\ttraining's auc: 0.918867\tvalid_1's auc: 0.820895\n",
      "2 auc: 0.8208953461684454\n",
      "Fold 3/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.834393\tvalid_1's auc: 0.815521\n",
      "[200]\ttraining's auc: 0.852032\tvalid_1's auc: 0.827826\n",
      "[300]\ttraining's auc: 0.865552\tvalid_1's auc: 0.835083\n",
      "[400]\ttraining's auc: 0.876247\tvalid_1's auc: 0.838759\n",
      "[500]\ttraining's auc: 0.885509\tvalid_1's auc: 0.841111\n",
      "[600]\ttraining's auc: 0.89358\tvalid_1's auc: 0.842172\n",
      "[700]\ttraining's auc: 0.900737\tvalid_1's auc: 0.84309\n",
      "[800]\ttraining's auc: 0.907143\tvalid_1's auc: 0.844168\n",
      "[900]\ttraining's auc: 0.912749\tvalid_1's auc: 0.844641\n",
      "[1000]\ttraining's auc: 0.917502\tvalid_1's auc: 0.844678\n",
      "Early stopping, best iteration is:\n",
      "[874]\ttraining's auc: 0.911394\tvalid_1's auc: 0.844838\n",
      "3 auc: 0.8448375969916051\n",
      "Fold 4/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.834931\tvalid_1's auc: 0.804991\n",
      "[200]\ttraining's auc: 0.852949\tvalid_1's auc: 0.820267\n",
      "[300]\ttraining's auc: 0.866414\tvalid_1's auc: 0.829672\n",
      "[400]\ttraining's auc: 0.877843\tvalid_1's auc: 0.834312\n",
      "[500]\ttraining's auc: 0.88766\tvalid_1's auc: 0.83682\n",
      "[600]\ttraining's auc: 0.896064\tvalid_1's auc: 0.83858\n",
      "[700]\ttraining's auc: 0.903412\tvalid_1's auc: 0.839809\n",
      "[800]\ttraining's auc: 0.909284\tvalid_1's auc: 0.840365\n",
      "[900]\ttraining's auc: 0.914227\tvalid_1's auc: 0.840277\n",
      "Early stopping, best iteration is:\n",
      "[810]\ttraining's auc: 0.909803\tvalid_1's auc: 0.840386\n",
      "4 auc: 0.8403857485236091\n",
      "Fold 5/5*1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[100]\ttraining's auc: 0.837488\tvalid_1's auc: 0.795002\n",
      "[200]\ttraining's auc: 0.855\tvalid_1's auc: 0.805862\n",
      "[300]\ttraining's auc: 0.869459\tvalid_1's auc: 0.814425\n",
      "[400]\ttraining's auc: 0.880367\tvalid_1's auc: 0.817607\n",
      "[500]\ttraining's auc: 0.889391\tvalid_1's auc: 0.819959\n",
      "[600]\ttraining's auc: 0.897579\tvalid_1's auc: 0.821767\n",
      "[700]\ttraining's auc: 0.904516\tvalid_1's auc: 0.822525\n",
      "[800]\ttraining's auc: 0.910007\tvalid_1's auc: 0.82258\n",
      "Early stopping, best iteration is:\n",
      "[720]\ttraining's auc: 0.905723\tvalid_1's auc: 0.822629\n",
      "5 auc: 0.8226285930575419\n",
      "auc = 0.834418 +/- 0.010447\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for training\n",
    "cols_to_drop = [\n",
    "    'id',\n",
    "    'target',\n",
    "]\n",
    "\n",
    "categorical = cat_names\n",
    "\n",
    "X = train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "y = train.target.values\n",
    "\n",
    "id_test = test.id.values\n",
    "X_test = test.drop(cols_to_drop[0], axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "print('train.shape = {}, test.shape = {}'.format(train.shape, test.shape))\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.01, \n",
    "    'verbose': -1,\n",
    "    'num_threads': 2,\n",
    "#     'scale_pos_weight' : int(train.target.mean()*10),\n",
    "    'is_unbalance' : 'true',\n",
    "}\n",
    "\n",
    "# Build the model\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "kf = StratifiedKFold(\n",
    "    n_splits=n_splits, \n",
    "    random_state=0)\n",
    "err_buf = []   \n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "for train_index, valid_index in kf.split(X, y):\n",
    "    print('Fold {}/{}*{}'.format(cnt + 1, n_splits, n_repeats))\n",
    "    params = lgb_params.copy() \n",
    "    \n",
    "    lgb_train = lgb.Dataset(\n",
    "        X.iloc[train_index], \n",
    "        y[train_index], \n",
    "        categorical_feature=categorical,\n",
    "    \n",
    "        )\n",
    "    lgb_train.raw_data = None\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        X.iloc[valid_index], \n",
    "        y[valid_index],\n",
    "        categorical_feature=categorical,\n",
    "        )\n",
    "    lgb_valid.raw_data = None\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=100000,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        early_stopping_rounds=150, \n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    if cnt == 0:\n",
    "        importance = model.feature_importance()\n",
    "        model_fnames = model.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1] > 0]\n",
    "        print('Important features:')\n",
    "        for i in range(60):\n",
    "            if i < len(tuples):\n",
    "                print(tuples[i])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        del importance, model_fnames, tuples\n",
    "\n",
    "    p = model.predict(X.iloc[valid_index], num_iteration=model.best_iteration)\n",
    "    err = roc_auc_score(y[valid_index], p)\n",
    "\n",
    "    print('{} auc: {}'.format(cnt + 1, err))\n",
    "\n",
    "    p = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p, dtype=np.float16)\n",
    "    else:\n",
    "        p_buf += np.array(p, dtype=np.float16)\n",
    "    err_buf.append(err)\n",
    "\n",
    "\n",
    "    cnt += 1\n",
    "    # if cnt > 0: # Comment this to run several folds\n",
    "    #     break\n",
    "\n",
    "    del model, lgb_train, lgb_valid, p\n",
    "    gc.collect\n",
    "\n",
    "err_mean = np.mean(err_buf)\n",
    "err_std = np.std(err_buf)\n",
    "print('auc = {:.6f} +/- {:.6f}'.format(err_mean, err_std))\n",
    "\n",
    "preds = p_buf/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Split\n",
    "# 5 auc: 0.8265728454896974\n",
    "# auc = 0.837760 +/- 0.009300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_pos_weight : 99 + stratify\n",
    "# 5 auc: 0.8009548197291523\n",
    "# auc = 0.810203 +/- 0.011326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_inbalanceb  + stratify\n",
    "# 5 auc: 0.8211641682998747\n",
    "# auc = 0.833885 +/- 0.010785  LB = 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_inbalanceb  + stratify + categorical\n",
    "# 5 auc: 0.8226285930575419\n",
    "# auc = 0.834418 +/- 0.010447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = id_test\n",
    "subm['prediction'] = preds\n",
    "subm.to_csv('submissions/lightgbm2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    from sklearn.metrics import log_loss\n",
    "    print(\"Training with params:\")\n",
    "    print(params)\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_test, label=y_test)\n",
    "    model = xgb.train(params, dtrain, params['num_round'])\n",
    "    predictions = model.predict(dvalid).reshape((X_test.shape[0], 7))\n",
    "    score = log_loss(y_test, predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'num_round': 100,\n",
    "             'learning_rate': hp.quniform('eta', 0.005, 0.05, 0.005),\n",
    "             'max_depth': hp.quniform('max_depth', 3, 14, 1),\n",
    "             'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "             'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma': hp.quniform('gamma', 0.5, 1, 0.01),\n",
    "             'colsample_bytree': hp.quniform('colsample_bytree', 0.4, 1, 0.05),\n",
    "             'num_class' : 7,\n",
    "             'eval_metric': 'merror',\n",
    "             'objective': 'multi:softprob',\n",
    "             'nthread' : 4,\n",
    "             'silent' : 1\n",
    "             }\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=10)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df, y, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_params = optimize(trials)\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
